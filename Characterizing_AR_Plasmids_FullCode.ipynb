{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAST results processing for Rep Proteins (to get Incompatibility type) and Virulence Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ALTHOUGH THE CODE IS WRITTEN TO PROCESS BLAST RESULTS FOR OTHER PROTEINS, ONLY THE REP AND VIR DATA WAS USED IN THIS PUBLICATION\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Only change the parameters inside here\n",
    "#  -------------------------------------------------------\n",
    "# Input the folder path (make sure it is r'path/')\n",
    "folderPathDad = r'/workdir/users/hgl28/CDC_Isolates/PlasmidTables/'\n",
    "folderPathMOB = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "\n",
    "# Input the name of the all of the types files (+ extension)\n",
    "filenameIncT = 'rep_results/Rep_Acc_IncType.txt'\n",
    "filenameMobT = 'mob_mpf_results/acc_oriTMob.txt'\n",
    "filenameMPFT = 'mob_mpf_results/acc_MPF2.txt'\n",
    "filenameT4CPT = 'mob_mpf_results/acc_T4CP_oriT.txt'\n",
    "filenameVirT = 'virulence/VF_core_acc.txt'\n",
    "\n",
    "# Input the name of the Blast Results files (+ extension)\n",
    "filenameRGI = 'rgi_plasmidORFs.tsv'\n",
    "filenameRepBR = 'rep_12-14-22.txt'\n",
    "filenameMobBR = 'mob_12-14-22.txt'\n",
    "filenameMPFBR = 'mpf_12-14-22.txt'\n",
    "filenameT4CPBR = 'T4CP_12-14-22.txt'\n",
    "filenameVirBR = 'virs_12-14-22_sed.txt'\n",
    "\n",
    "#  Input the name of the ORF ID file (+ extension)\n",
    "filenamePID = 'plasmidORF_IDs_12-14-22.txt'\n",
    "\n",
    "# Input the Output ORF and Plasmid files (+ extension)\n",
    "filenameOoutF = 'RGI_tab_12-14-22.csv'\n",
    "# ------------------------------------------\n",
    "\n",
    "# Loading the type files\n",
    "IC = pd.read_csv(folderPathDad + filenameIncT, delimiter='\\t', header=None)\n",
    "IC.columns = [\"Acc\",\"INC\"]\n",
    "MOB = pd.read_csv(folderPathDad + filenameMobT, delimiter='\\t', header=None)\n",
    "MOB.columns = [\"Acc\",\"MOB\"]\n",
    "MPF = pd.read_csv(folderPathDad + filenameMPFT, delimiter='\\t', header=None)\n",
    "MPF.columns = [\"Acc\",\"MPF\"]\n",
    "T4CP = pd.read_csv(folderPathDad + filenameT4CPT, delimiter='\\t', header=None)\n",
    "T4CP.columns = [\"Acc\",\"T4CP\"]\n",
    "VIR = pd.read_csv(folderPathDad + filenameVirT, delimiter='\\t', header=None)\n",
    "VIR.columns = [\"Acc\",\"VIR\"]\n",
    "# Loading the Blast results files\n",
    "RGIr = pd.read_csv(folderPathMOB + filenameRGI, delimiter='\\t', header=0)\n",
    "RepBR = pd.read_csv(folderPathMOB + filenameRepBR, delimiter='\\t', header=None)\n",
    "BRNames = RepBR.columns\n",
    "RepBR = RepBR[BRNames[0:5]]\n",
    "RepBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "MobBR = pd.read_csv(folderPathMOB + filenameMobBR, delimiter='\\t', header=None)\n",
    "BRNames = MobBR.columns\n",
    "MobBR = MobBR[BRNames[0:5]]\n",
    "MobBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "MPFBR = pd.read_csv(folderPathMOB + filenameMPFBR, delimiter='\\t', header=None)\n",
    "BRNames = MPFBR.columns\n",
    "MPFBR = MPFBR[BRNames[0:5]]\n",
    "MPFBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "T4CPBR = pd.read_csv(folderPathMOB + filenameT4CPBR, delimiter='\\t', header=None)\n",
    "BRNames = T4CPBR.columns\n",
    "T4CPBR = T4CPBR[BRNames[0:5]]\n",
    "T4CPBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "VirBR = pd.read_csv(folderPathMOB + filenameVirBR, delimiter='\\t', header=None)\n",
    "BRNames = VirBR.columns\n",
    "VirBR = VirBR[BRNames[0:5]]\n",
    "VirBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "\n",
    "# Loading the Plasmid ID file\n",
    "PlID = pd.read_csv(folderPathMOB + filenamePID, delimiter='\\t', header=0)\n",
    "\n",
    "#Creating output file from RGI file\n",
    "RGIgenes = RGIr[[\"ORF_ID\", \"Best_Hit_ARO\"]].copy()\n",
    "FullRGI = PlID.merge(RGIgenes, how = 'left', on = 'ORF_ID')\n",
    "print(RGIgenes)\n",
    "print(PlID)\n",
    "print(FullRGI)\n",
    "FullRGI.to_csv(folderPathMOB + filenameOoutF)\n",
    "print(\"Antibiotic Resistance Genes Added\")\n",
    "\n",
    "# Loading output file\n",
    "ORF_OF = pd.read_csv(folderPathMOB + filenameOoutF, delimiter=',', header=0)\n",
    "\n",
    "# Setting up the Thresholds\n",
    "PIDT = 50\n",
    "QcovT = 50\n",
    "QcovT2 = 70\n",
    "EvalT = 10e-5\n",
    "counter = 0\n",
    "totalPlIDs = len(PlID)\n",
    "RepBRIndexHit = []\n",
    "\n",
    "\n",
    "#Add Inc, MOB, MPF, T4CP, and Vir Types to Blast Results tables\n",
    "\n",
    "#Rep -----------------------------------------------------------------------------------\n",
    "RepIndex = RepBR.index\n",
    "for i in tqdm(RepIndex):\n",
    "    RepBR.at[i, \"Query\"] = RepBR.loc[i].Query[:-2]\n",
    "RepBRAcc = RepBR.merge(IC, how = 'inner', left_on = 'Query', right_on = 'Acc')\n",
    "\n",
    "#MOB -----------------------------------------------------------------------------------\n",
    "MobIndex = MobBR.index\n",
    "for i in tqdm(MobIndex):\n",
    "    MobBR.at[i, \"Query\"] = MobBR.loc[i].Query[:-2]\n",
    "MobBRAcc = MobBR.merge(MOB, how = 'inner', left_on = 'Query', right_on = 'Acc')\n",
    "\n",
    "#MPF -----------------------------------------------------------------------------------\n",
    "MPFIndex = MPFBR.index\n",
    "for i in tqdm(MPFIndex):\n",
    "    MPFBR.at[i, \"Query\"] = MPFBR.loc[i].Query[:-2]\n",
    "MPFBRAcc = MPFBR.merge(MPF, how = 'inner', left_on = 'Query', right_on = 'Acc')\n",
    "\n",
    "#T4CP -----------------------------------------------------------------------------------\n",
    "T4CPIndex = T4CPBR.index\n",
    "for i in tqdm(T4CPIndex):\n",
    "    T4CPBR.at[i, \"Query\"] = T4CPBR.loc[i].Query[:-2]\n",
    "T4CPBRAcc = T4CPBR.merge(T4CP, how = 'inner', left_on = 'Query', right_on = 'Acc')\n",
    "\n",
    "#VIR -----------------------------------------------------------------------------------\n",
    "VirIndex = VirBR.index\n",
    "VirBRAcc = VirBR.merge(VIR, how = 'inner', left_on = 'Query', right_on = 'Acc')\n",
    "print(VirBR)\n",
    "print(VirIndex)\n",
    "print(VIR)\n",
    "print(VirBRAcc)\n",
    "\n",
    "\n",
    "#BLAST scans\n",
    "\n",
    "#Rep -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkRep = RepBRAcc.Subject == i\n",
    "    if ChkRep.sum() > 0:\n",
    "        tempDFRep = RepBRAcc[ChkRep]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFRep.index:\n",
    "            tempRowRep = tempDFRep.loc[iii]\n",
    "            if tempRowRep.PID >= PIDT and tempRowRep.Qcov >= QcovT and tempRowRep.Eval <= EvalT:\n",
    "                if tempRowRep.Qcov >= coverage:\n",
    "                    coverage = tempRowRep.Qcov\n",
    "                    current_best_idx = iii\n",
    "        RepBRIndexHit = np.append(RepBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"Rep Blast Scanning Finished! You got \" + str(len(RepBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "MobBRIndexHit = []\n",
    "totalPlIDs\n",
    "#MOB -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkMOB = MobBR.Subject == i\n",
    "    if ChkMOB.sum() > 0:\n",
    "        tempDFMOB = MobBR[ChkMOB]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFMOB.index:\n",
    "            tempRowMOB = tempDFMOB.loc[iii]\n",
    "            if tempRowMOB.PID >= PIDT and tempRowMOB.Qcov >= QcovT2:\n",
    "                if tempRowRep.Qcov >= coverage:\n",
    "                    coverage = tempRowRep.Qcov\n",
    "                    current_best_idx = iii\n",
    "        MobBRIndexHit = np.append(MobBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"Mob Blast Scanning Finished! You got \" + str(len(MobBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "MPFBRIndexHit = []\n",
    "\n",
    "#MPF -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkMPF = MPFBR.Subject == i\n",
    "    if ChkMPF.sum() > 0:\n",
    "        tempDFMPF = MPFBR[ChkMPF]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFMPF.index:\n",
    "            tempRowMPF = tempDFMPF.loc[iii]\n",
    "            if tempRowMPF.PID >= PIDT and tempRowMPF.Qcov >= QcovT2:\n",
    "                if tempRowRep.Qcov >= coverage:\n",
    "                    coverage = tempRowRep.Qcov\n",
    "                    current_best_idx = iii\n",
    "        MPFBRIndexHit = np.append(MPFBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"MPF Blast Scanning Finished! You got \" + str(len(MPFBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "T4CPBRIndexHit = []\n",
    "\n",
    "#T4CP -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkT4CP = T4CPBR.Subject == i\n",
    "    if ChkT4CP.sum() > 0:\n",
    "        tempDFT4CP = T4CPBR[ChkT4CP]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFT4CP.index:\n",
    "            tempRowT4CP = tempDFT4CP.loc[iii]\n",
    "            if tempRowT4CP.PID >= PIDT and tempRowT4CP.Qcov >= QcovT2:\n",
    "                if tempRowRep.Qcov >= coverage:\n",
    "                    coverage = tempRowRep.Qcov\n",
    "                    current_best_idx = iii\n",
    "        T4CPBRIndexHit = np.append(T4CPBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"T4CP Blast Scanning Finished! You got \" + str(len(T4CPBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "VirBRIndexHit = []\n",
    "\n",
    "#VIR -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkVIR = VirBR.Subject == i\n",
    "    if ChkVIR.sum() > 0:\n",
    "        tempDFVIR = VirBR[ChkVIR]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFVIR.index:\n",
    "            tempRowVIR = tempDFVIR.loc[iii]\n",
    "            if tempRowVIR.PID >= PIDT and tempRowVIR.Qcov >= QcovT2 and tempRowRep.Eval <= EvalT:\n",
    "                if tempRowRep.Qcov >= coverage:\n",
    "                    coverage = tempRowRep.Qcov\n",
    "                    current_best_idx = iii\n",
    "        VirBRIndexHit = np.append(VirBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"Vir Blast Scanning Finished! You got \" + str(len(VirBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "\n",
    "\n",
    "\n",
    "# Scan Hits and add to table\n",
    "\n",
    "#Rep -----------------------------------------------------------------------------------\n",
    "RepHits = RepBRAcc.iloc[RepBRIndexHit] \n",
    "RepHitsmall = RepHits[[\"Subject\", \"INC\"]].copy().drop_duplicates()\n",
    "RepOF = ORF_OF.merge(RepHitsmall, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "RepOF = RepOF[[\"ORF_ID\", \"Best_Hit_ARO\", \"INC\"]].copy()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RepOF.to_csv(folderPathMOB + \"Inc_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"Inc Type Added \", len(RepOF))\n",
    "\n",
    "#MOB -----------------------------------------------------------------------------------\n",
    "MobHits = MobBRAcc.iloc[MobBRIndexHit]\n",
    "MobHitsmall = MobHits[[\"Subject\", \"MOB\"]].copy().drop_duplicates()\n",
    "MobOF = ORF_OF.merge(MobHitsmall, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "MobOF = MobOF[[\"ORF_ID\", \"Best_Hit_ARO\", \"MOB\"]].copy()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "MobOF.to_csv(folderPathMOB + \"Mob_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"MOB Type Added \", len(MobOF))\n",
    "\n",
    "#MPF -----------------------------------------------------------------------------------\n",
    "MPFHits = MPFBRAcc.iloc[MPFBRIndexHit]\n",
    "MPFHitsmall = MPFHits[[\"Subject\", \"MPF\"]].copy().drop_duplicates()\n",
    "MPFOF = ORF_OF.merge(MPFHitsmall, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "MPFOF = MPFOF[[\"ORF_ID\", \"Best_Hit_ARO\", \"MPF\"]].copy()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "MPFOF.to_csv(folderPathMOB + \"MPF_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"MPF Type Added \", len(MPFOF))\n",
    "\n",
    "#T4CP -----------------------------------------------------------------------------------\n",
    "T4CPHits = T4CPBRAcc.iloc[T4CPBRIndexHit]\n",
    "T4CPHitsmall = T4CPHits[[\"Subject\", \"T4CP\"]].copy().drop_duplicates()\n",
    "T4CPOF = ORF_OF.merge(T4CPHitsmall, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "T4CPOF = T4CPOF[[\"ORF_ID\", \"Best_Hit_ARO\", \"T4CP\"]].copy()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "T4CPOF.to_csv(folderPathMOB + \"T4CP_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"T4CP Genes Added \", len(T4CPOF))\n",
    "\n",
    "#VIR -----------------------------------------------------------------------------------\n",
    "VirHits = VirBRAcc.iloc[VirBRIndexHit]\n",
    "VirHitsmall = VirHits[[\"Subject\", \"VIR\"]].copy().drop_duplicates()\n",
    "VirOF = ORF_OF.merge(VirHitsmall, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "VirOF = VirOF[[\"ORF_ID\", \"Best_Hit_ARO\", \"VIR\"]].copy()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "VirOF.to_csv(folderPathMOB + \"VIR_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"Virulence Genes Added \", len(VirOF))\n",
    "\n",
    "#Making the final output file\n",
    "RepFinal = RepOF[[\"ORF_ID\", \"Best_Hit_ARO\", \"INC\"]].copy().drop_duplicates()\n",
    "MOBFinal = MobOF[[\"ORF_ID\",\"MOB\"]].copy().drop_duplicates()\n",
    "MPFFinal = MPFOF[[\"ORF_ID\",\"MPF\"]].copy().drop_duplicates()\n",
    "T4CPFinal = T4CPOF[[\"ORF_ID\",\"T4CP\"]].copy().drop_duplicates()\n",
    "VIRFinal = VirOF[[\"ORF_ID\",\"VIR\"]].copy().drop_duplicates()\n",
    "\n",
    "Merge = RepFinal.merge(MOBFinal, how='outer', on='ORF_ID')\n",
    "Merge = Merge.merge(MPFFinal,  how='outer', on='ORF_ID')\n",
    "Merge = Merge.merge(T4CPFinal,  how='outer', on='ORF_ID')\n",
    "FinalOF = Merge.merge(VIRFinal,  how='outer', on='ORF_ID').drop_duplicates()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "FinalOF.to_csv(folderPathMOB + \"Final_ORF_tab_\" + dt_string + \".csv\")\n",
    "print(\"Everything Finished \", len(FinalOF))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding MOBtyper and RGI results to plasmid table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#File and Folder names (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "FolderPath = r\"/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/\"\n",
    "MD_name = \"metadata_01-12-23.csv\"\n",
    "Plastab_name = \"Plasmid_tab2_01-09-23.csv\"\n",
    "mobFile = \"12-14-22_MobTyperResults_sed.txt\"\n",
    "filenameRGI = 'Plasmid_Tab_withHits_2023-01-09_sed.csv'\n",
    "\n",
    "\n",
    "#Read files\n",
    "Plastab = pd.read_csv(FolderPath + Plastab_name, delimiter=\",\", header=0)\n",
    "MDa = pd.read_csv(FolderPath + MD_name, delimiter=\",\", header=0)\n",
    "mobtypertab = pd.read_csv(FolderPath + mobFile, delimiter=\"\\t\", header=0)\n",
    "mobtypertab_short = mobtypertab[[\"sample_id\", \"rep_type(s)\", \"relaxase_type(s)\", \"mpf_type\", \"orit_type(s)\", \"predicted_mobility\", \"predicted_host_range_overall_rank\"]].copy()\n",
    "RGIr = pd.read_csv(FolderPath + filenameRGI, delimiter=',', header=0)\n",
    "\n",
    "#Adding ARG data\n",
    "RGIgenes = RGIr[[\"Plasmid_ID\", \"ARGs\", \"Virulence\"]].copy()\n",
    "FullRGI = Plastab.merge(RGIgenes, how = 'left', on = 'Plasmid_ID')\n",
    "Plastab = FullRGI[[\"Plasmid_ID\", \"Length\", \"GC\", \"ARGs\", \"Virulence\"]].copy()\n",
    "print(\"Antibiotic Resistance and Virulence Genes Added\")\n",
    "\n",
    "#Merging MOB-typer data with plasmid table\n",
    "Plastab_Merge = Plastab.merge(mobtypertab_short, how='left', left_on='Plasmid_ID', right_on='sample_id')\n",
    "Plastab_clean = Plastab_Merge[[\"Plasmid_ID\", \"Length\", \"GC\", \"ARGs\", \"Virulence\", \"rep_type(s)\", \"relaxase_type(s)\", \"mpf_type\", \"orit_type(s)\", \"predicted_mobility\", \"predicted_host_range_overall_rank\"]].copy()\n",
    "print(\"MOB-typer data added\")\n",
    "\n",
    "#Add Metadata to Plasmid Table\n",
    "MDalist = []\n",
    "for i in MDa[\"Acc\"]:\n",
    "    MDalist.append(i)\n",
    "\n",
    "append = \".1\"\n",
    "MDAlist_suf = [suf + append for suf in MDalist]\n",
    "counter = 0\n",
    "for ii in MDa.index:\n",
    "    MDa.loc[ii, \"Acc\"] = MDAlist_suf[counter]\n",
    "    counter+=1\n",
    "\n",
    "Merged = Plastab_clean.merge(MDa, how='left', right_on='Acc', left_on='Plasmid_ID', copy=False)\n",
    "Merged = Merged[[\"Genus\", \"Organism\", \"AR_Bank_ID\", \"Plasmid_ID\", \"Length\", \"GC\", \"ARGs\", \"rep_type(s)\", \"relaxase_type(s)\", \"mpf_type\", \"orit_type(s)\", \"predicted_mobility\", \"predicted_host_range_overall_rank\", \"Virulence\"]].copy()\n",
    "print(\"Isolate data added\")\n",
    "Merged.to_csv(FolderPath + \"PlasmidTab_mob_withMDa_01-12-23.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding rmsFinder results to plasmid table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input the folder path (make sure it is r'path/')\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "# Filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "filenameRE = 'rmsFinder/plasmid_ORFs_Rmsfinder_RE.csv'\n",
    "filenameMT = 'rmsFinder/plasmid_ORFs_Rmsfinder_MT.csv'\n",
    "filenamePID = 'plasmidORF_IDs_12-14-22.txt'\n",
    "filenamePLid = 'plasmidIDs_01-23-23.txt'\n",
    "filenamePlOF = 'Plasmid_Tab_sed_01-23-23.csv'\n",
    "filenameORF_OF = 'InterPlasTabs/RGI_tab_12-14-22.csv'\n",
    "\n",
    "# Loading the Blast results files\n",
    "REtab = pd.read_csv(folderPath + filenameRE, delimiter=',', header=0)\n",
    "MTtab = pd.read_csv(folderPath + filenameMT, delimiter=',', header=0)\n",
    "\n",
    "#Loading Output Files\n",
    "ORF_OF = pd.read_csv(folderPath + filenameORF_OF, delimiter=',', header=0)\n",
    "Pl_OF = pd.read_csv(folderPath + filenamePlOF, delimiter=',', header=0)\n",
    "\n",
    "# Loading the Plasmid ID files\n",
    "PlID = pd.read_csv(folderPath + filenamePID, delimiter='\\t', header=0)\n",
    "PLasmidID = pd.read_csv(folderPath + filenamePLid, delimiter='\\t', header=0)\n",
    "PLasmidID = PLasmidID.drop_duplicates()\n",
    "\n",
    "# Setting up the Thresholds\n",
    "PIDT = 50\n",
    "EvalT = 10e-5\n",
    "counter = 0\n",
    "totalPlIDs = len(PlID)\n",
    "PlasmidIDS = len(PLasmidID)\n",
    "REIndexHit = []\n",
    "MTIndexHit = []\n",
    "\n",
    "#rmsFinder Results scans\n",
    "\n",
    "#Restriction Enzymes -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkRE = REtab.qseqid == i\n",
    "    if ChkRE.sum() > 0:\n",
    "        tempDFRE = REtab[ChkRE]\n",
    "        current_best_idx = 0\n",
    "        for iii in tempDFRE.index:\n",
    "            tempRowTA = tempDFRE.loc[iii]\n",
    "            if tempRowTA.pident >= PIDT and tempRowTA.evalue <= EvalT and tempRowTA.coverage_threshold_met == True:\n",
    "                current_best_idx = iii\n",
    "        REIndexHit = np.append(REIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"RE rmsFinder results Scanning Finished! You got \" + str(len(REIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "\n",
    "#Methylases -----------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkMT = MTtab.qseqid == i\n",
    "    if ChkMT.sum() > 0:\n",
    "        tempDFMT = MTtab[ChkMT]\n",
    "        current_best_idx = 0\n",
    "        for iii in tempDFMT.index:\n",
    "            tempRowTA = tempDFMT.loc[iii]\n",
    "            if tempRowTA.pident >= PIDT and tempRowTA.evalue <= EvalT and tempRowTA.coverage_threshold_met == True:\n",
    "                current_best_idx = iii\n",
    "        MTIndexHit = np.append(MTIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"MT rmsFinder results Scanning Finished! You got \" + str(len(MTIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Scan Hits and add to table\n",
    "#Restriction Enzymes -----------------------------------------------------------------------------------\n",
    "REHits = REtab.iloc[REIndexHit] \n",
    "Re_OF = ORF_OF.merge(REHits, how='left', left_on='ORF_ID',right_on='qseqid')\n",
    "ReOF = Re_OF[[\"ORF_ID\", \"Best_Hit_ARO\", \"sseqid\"]].copy()\n",
    "dummytabname = 'Plasmid_tab2_01-09-23.csv'\n",
    "dummytab = pd.read_csv(folderPath + dummytabname, delimiter=',', header=0)\n",
    "for i in tqdm(dummytab[\"Plasmid_ID\"]):\n",
    "    index = dummytab[dummytab.Plasmid_ID == i]\n",
    "    Chk = ReOF[\"ORF_ID\"].str.contains(i)\n",
    "    match = ReOF[Chk]\n",
    "    for ii in match.index:\n",
    "        temprow = match.loc[ii]\n",
    "        #TA\n",
    "        NewARG = str(temprow[2])\n",
    "        tempstr = dummytab.at[dummytab[dummytab.Plasmid_ID == i].index[0],\"Restriction Enzymes\"]\n",
    "        temptype = type(dummytab.at[dummytab[dummytab.Plasmid_ID == i].index[0],\"Restriction Enzymes\"])\n",
    "        if temptype == str:\n",
    "            dummytab.at[dummytab[dummytab.Plasmid_ID == i].index[0],\"Restriction Enzymes\"] = tempstr + \" \" + NewARG\n",
    "        else:\n",
    "            dummytab.at[dummytab[dummytab.Plasmid_ID == i].index[0],\"Restriction Enzymes\"] = NewARG\n",
    "\n",
    "#Methylases -----------------------------------------------------------------------------------\n",
    "MTHits = MTtab.iloc[REIndexHit] \n",
    "Mt_OF = ORF_OF.merge(MTHits, how='left', left_on='ORF_ID',right_on='qseqid')\n",
    "MtOF = Mt_OF[[\"ORF_ID\", \"Best_Hit_ARO\", \"sseqid\"]].copy()\n",
    "dummytabname = 'Plasmid_tab3_01-09-23.csv'\n",
    "dummytab2 = pd.read_csv(folderPath + dummytabname, delimiter=',', header=0)\n",
    "for i in tqdm(dummytab2[\"Plasmid_ID\"]):\n",
    "    index = dummytab2[dummytab2.Plasmid_ID == i]\n",
    "    Chk = MtOF[\"ORF_ID\"].str.contains(i)\n",
    "    match = MtOF[Chk]\n",
    "    for ii in match.index:\n",
    "        temprow = match.loc[ii]\n",
    "        #TA\n",
    "        NewARG = str(temprow[2])\n",
    "        tempstr = dummytab2.at[dummytab2[dummytab2.Plasmid_ID == i].index[0],\"Methylases\"]\n",
    "        temptype = type(dummytab2.at[dummytab2[dummytab2.Plasmid_ID == i].index[0],\"Methylases\"])\n",
    "        if temptype == str:\n",
    "            dummytab2.at[dummytab2[dummytab2.Plasmid_ID == i].index[0],\"Methylases\"] = tempstr + \" \" + NewARG\n",
    "        else:\n",
    "            dummytab2.at[dummytab2[dummytab2.Plasmid_ID == i].index[0],\"Methylases\"] = NewARG\n",
    "\n",
    "#Final tables and finish\n",
    "Plastab_0123 = dummytab2.merge(dummytab, how='left', on='Plasmid_ID')\n",
    "Plastab_012323 = Pl_OF.merge(Plastab_0123, how='left', on='Plasmid_ID')\n",
    "Plastab_012323 = Plastab_012323[[\"Genus\",\"Organism\",\"AR_Bank_ID\",\"Plasmid_ID\",\"Length\",\"GC\",\"ARGs\",\"rep_type(s)\",\"relaxase_type(s)\",\"mpf_type\",\"orit_type(s)\",\"predicted_mobility\",\"predicted_host_range_overall_rank\",\"Virulence\", \"Protein T-AT\", \"RNA T-AT\", \"Restriction Enzymes\", \"Methylases\"]].copy()\n",
    "Plastab_012323.to_csv(folderPath + 'Plasmid_Tab_full_01-31-23.csv')\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting plasmid metadata (downloaded from NCBI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Plasmid Metadata from XML file\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "xmlPath = r\"/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/Plasmid_Info_NCBI.xml\"\n",
    "FolderPath = r\"/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/\"\n",
    "\n",
    "tree = ET.parse(xmlPath)\n",
    "root = tree.getroot()\n",
    "print(root.tag, root.attrib)\n",
    "\n",
    "Acctab = []\n",
    "Nametab = []\n",
    "Genustab = []\n",
    "ARbanktab = []\n",
    "\n",
    "for Acc in root.iter('Textseq-id_accession'):\n",
    "    Acctab.append(Acc.text)\n",
    "print(len(Acctab))\n",
    "\n",
    "for Name in root.iter('Org-ref_taxname'):\n",
    "    Nametab.append(Name.text)\n",
    "print(len(Nametab))\n",
    "\n",
    "for Genus in root.iter(\"BinomialOrgName_genus\"):\n",
    "    Genustab.append(Genus.text)\n",
    "print(len(Genustab))\n",
    "\n",
    "for mod in root.iter(\"OrgMod\"):\n",
    "    for subtype in mod.findall(\"OrgMod_subtype\"):\n",
    "        if subtype.text == '2':\n",
    "            for ARbankID in mod.findall(\"OrgMod_subname\"):\n",
    "                ARbanktab.append(ARbankID.text)\n",
    "print(len(ARbanktab))\n",
    "\n",
    "MD_df = pd.DataFrame(list(zip(Acctab, Genustab, Nametab, ARbanktab)), columns=['Acc', 'Genus', 'Organism', 'AR_Bank_ID'])\n",
    "MD_df.to_csv(FolderPath + \"metadata_01-12-23.csv\")\n",
    "\n",
    "#Adding said plasmid metadata to the plasmid table\n",
    "\n",
    "FolderPath = r\"/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/\"\n",
    "MD_name = \"metadata_01-10-23.csv\"\n",
    "Plastab_name = \"Plasmid_Tab_withHits_2023-01-09_sed.csv\"\n",
    "\n",
    "Plastab = pd.read_csv(FolderPath + Plastab_name, delimiter=\",\", header=0)\n",
    "MDa = pd.read_csv(FolderPath + MD_name, delimiter=\",\", header=0)\n",
    "\n",
    "#Add Metadata to Plasmid Table\n",
    "MDalist = []\n",
    "for i in MDa[\"Acc\"]:\n",
    "    MDalist.append(i)\n",
    "\n",
    "append = \".1\"\n",
    "MDAlist_suf = [suf + append for suf in MDalist]\n",
    "counter = 0\n",
    "for ii in MDa.index:\n",
    "    MDa.loc[ii, \"Acc\"] = MDAlist_suf[counter]\n",
    "    counter+=1\n",
    "\n",
    "Merged = Plastab.merge(MDa, how='left', right_on='Acc', left_on='Plasmid_ID', copy=False)\n",
    "Merged = Merged[[\"Organism\",\"AR_Bank_ID\",\"Plasmid_ID\",\"Length\",\"GC\",\"ARGs\",\"Inc_Type\",\"MOB_Type\",\"MPF_Type\",\"T4CP\",\"Virulence\"]].copy()\n",
    "Merged.to_csv(FolderPath + \"PlasmidTab_withMDa_01-10-23.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAST results processing for Partitioning Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blast Scanning for Par Proteins\n",
    "\n",
    "#Re running imports and file loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input the folder path (make sure it is r'path/') and filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "filenamePID = 'plasmidORF_IDs_12-14-22.txt'\n",
    "filenamePLid = 'plasmidIDs_01-23-23.txt'\n",
    "filenamePlOF = 'Plasmid_Tab_sed_01-23-23.csv'\n",
    "filenameORF_OF = 'InterPlasTabs/RGI_tab_12-14-22.csv'\n",
    "filename_parBR = 'Partitioning/all_pars_sed_02-02-23.txt'\n",
    "\n",
    "\n",
    "#Read Blast Results\n",
    "parBR = pd.read_csv(folderPath + filename_parBR, delimiter='\\t', header=None)\n",
    "parBRNames = parBR.columns\n",
    "parBR = parBR[parBRNames[0:5]]\n",
    "parBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "\n",
    "# Setting up the Thresholds\n",
    "PIDT = 80\n",
    "QcovT2 = 70\n",
    "EvalT = 10e-5\n",
    "counter = 0\n",
    "totalPlIDs = len(PlID)\n",
    "ParBRIndexHit = []\n",
    "\n",
    "#Add Par Protein Families to Blast Results tables\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "ParAcc = pd.read_csv(folderPath + 'Partitioning/all_pars_titles.csv', delimiter=',',header=0)\n",
    "parBR = parBR.merge(ParAcc, how = 'inner', left_on = 'Query', right_on = 'ACC')\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkPar = parBR.Subject == i\n",
    "    if ChkPar.sum() > 0:\n",
    "        tempDFPar = parBR[ChkPar]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFPar.index:\n",
    "            tempRowPar = tempDFPar.loc[iii]\n",
    "            if tempRowPar.PID >= PIDT and tempRowPar.Qcov >= QcovT2 and tempRowPar.Eval <= EvalT:\n",
    "                if tempRowPar.Qcov >= coverage:\n",
    "                    coverage = tempRowPar.Qcov\n",
    "                    current_best_idx = iii\n",
    "        ParBRIndexHit = np.append(ParBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"Partition Protein Blast Scanning Finished! You got \" + str(len(ParBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "\n",
    "# Scan Hits and add to table\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "ParHits = parBR.iloc[ParBRIndexHit] \n",
    "ParOF = ORF_OF.merge(ParHits, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "ParOF = ParOF[[\"ORF_ID\", \"PAR\"]].copy().drop_duplicates()\n",
    "print(\"Par Proteins Added \", len(ParOF))\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "ParOF.to_csv(folderPath + \"Par_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"All done!\")\n",
    "\n",
    "#Adding stuff to plasmid table\n",
    "PlastabOF = pd.read_csv(folderPath + \"sed_PlasmidTab_02-01-23.csv\", delimiter=',', header=0)\n",
    "Plastab = pd.read_csv(folderPath + 'Plasmid_tab2_01-09-23.csv', delimiter=',', header=0)\n",
    "ORFtab = ParOF.dropna(subset=[\"PAR\"])\n",
    "#Identify plasmid ORFs and replace empty cells with hits from ORFs in plasmid table\n",
    "for i in tqdm(PLasmidID[\"Plasmid_ID\"]):\n",
    "    index = Plastab[Plastab.Plasmid_ID == i]\n",
    "    Chk = ORFtab[\"ORF_ID\"].str.contains(i)\n",
    "    match = ORFtab[Chk]\n",
    "    for ii in match.index:\n",
    "        temprow = match.loc[ii]\n",
    "        #ARGs\n",
    "        NewARG = str(temprow[1])\n",
    "        tempstr = Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Par\"]\n",
    "        temptype = type(Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Par\"])\n",
    "        if temptype == str:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Par\"] = tempstr + \" \" + NewARG\n",
    "        else:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Par\"] = NewARG\n",
    "\n",
    "\n",
    "#Finishing touches and output    \n",
    "print(\"Everything Finished\")\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "Plastab.to_csv(folderPath + \"Plasmid_TabPar_withHits_\"+ dt_string + \".csv\")\n",
    "\n",
    "Full_Plastab = pd.read_csv(folderPath + \"sed_PlasmidTab_02-01-23.csv\", delimiter=',', header=0)\n",
    "Plastab = pd.read_csv(folderPath + 'Plasmid_TabPar_withHits_2023-02-02_17-01-19.csv', delimiter=',', header=0)\n",
    "Plastab.drop(columns=[\"Length\", \"GC\"], inplace=True)\n",
    "Full_merge = Full_Plastab.merge(Plastab, how='left', on=[\"Plasmid_ID\"])\n",
    "Full_mergeOF = Full_merge[[\"Genus\",\"Organism\",\"AR_Bank_ID\",\"Plasmid_ID\",\"Length\",\"GC\",\"ARGs\",\"rep_type(s)\",\"relaxase_type(s)\",\"mpf_type\",\"orit_type(s)\",\"predicted_mobility\",\"predicted_host_range_overall_rank\",\"Virulence\",\"Protein T-AT\",\"RNA T-AT\",\"Restriction Enzymes\",\"Methylases\",\"Par\"]]\n",
    "Full_mergeOF.to_csv(folderPath + 'Plasmid_Tab_Full_02-06-23.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAST results processing for Plasmid SOS Inhibition Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeating Partitioning code for Plasmid SOS Inhibition\n",
    "#Blast Scanning for Psi Proteins\n",
    "#Re running imports and file loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input the folder path (make sure it is r'path/') and filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "filename_psiBR = 'PlasmidSOS/psis_02-06-23.txt'\n",
    "filenamePID = 'plasmidORF_IDs_12-14-22.txt'\n",
    "filenamePLid = 'plasmidIDs_01-23-23.txt'\n",
    "filenamePlOF = 'Plasmid_Tab_Full_02-06-23.csv'\n",
    "filenameORF_OF = 'InterPlasTabs/RGI_tab_12-14-22.csv'\n",
    "\n",
    "# Loading the Blast results files\n",
    "psiBR = pd.read_csv(folderPath + filename_psiBR, delimiter='\\t', header=None)\n",
    "psiBRNames = psiBR.columns\n",
    "psiBR = psiBR[psiBRNames[0:5]]\n",
    "psiBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "\n",
    "#Loading Output Files\n",
    "ORF_OF = pd.read_csv(folderPath + filenameORF_OF, delimiter=',', header=0)\n",
    "Pl_OF = pd.read_csv(folderPath + filenamePlOF, delimiter=',', header=0)\n",
    "\n",
    "# Loading the Plasmid ID files\n",
    "PlID = pd.read_csv(folderPath + filenamePID, delimiter='\\t', header=0)\n",
    "PLasmidID = pd.read_csv(folderPath + filenamePLid, delimiter='\\t', header=0)\n",
    "PLasmidID = PLasmidID.drop_duplicates()\n",
    "\n",
    "# Setting up the Thresholds\n",
    "PIDT = 80\n",
    "QcovT2 = 70\n",
    "EvalT = 10e-5\n",
    "counter = 0\n",
    "totalPlIDs = len(PlID)\n",
    "PsiBRIndexHit = []\n",
    "\n",
    "\n",
    "#Add Psi Protein Families to Blast Results tables\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "PsiAcc = pd.read_csv(folderPath + 'PlasmidSOS/allpsis_titles.csv', delimiter=',',header=0)\n",
    "psiBR = psiBR.merge(PsiAcc, how = 'inner', left_on = 'Query', right_on = 'ACC')\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkPsi = psiBR.Subject == i\n",
    "    if ChkPsi.sum() > 0:\n",
    "        tempDFPar = psiBR[ChkPsi]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFPar.index:\n",
    "            tempRowPar = tempDFPar.loc[iii]\n",
    "            if tempRowPar.PID >= PIDT and tempRowPar.Qcov >= QcovT2 and tempRowPar.Eval <= EvalT:\n",
    "                if tempRowPar.Qcov >= coverage:\n",
    "                    coverage = tempRowPar.Qcov\n",
    "                    current_best_idx = iii\n",
    "        PsiBRIndexHit = np.append(PsiBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"Plasmid SOS Inhibition Protein Blast Scanning Finished! You got \" + str(len(PsiBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "\n",
    "# Scan Hits and add to table\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "PsiHits = psiBR.iloc[PsiBRIndexHit] \n",
    "PsiOF = ORF_OF.merge(PsiHits, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "PsiOF = PsiOF[[\"ORF_ID\", \"PSI\"]].copy().drop_duplicates()\n",
    "print(\"Psi Proteins Added \", len(PsiOF))\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "PsiOF.to_csv(folderPath + \"Psi_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"All done!\")\n",
    "\n",
    "\n",
    "#Adding stuff to plasmid table\n",
    "Plastab = pd.read_csv(folderPath + 'Plasmid_tab2_01-09-23.csv', delimiter=',', header=0)\n",
    "ORFtab = PsiOF.dropna(subset=[\"PSI\"])\n",
    "#Identify plasmid ORFs and replace empty cells with hits from ORFs in plasmid table\n",
    "for i in tqdm(PLasmidID[\"Plasmid_ID\"]):\n",
    "    index = Plastab[Plastab.Plasmid_ID == i]\n",
    "    Chk = ORFtab[\"ORF_ID\"].str.contains(i)\n",
    "    match = ORFtab[Chk]\n",
    "    for ii in match.index:\n",
    "        temprow = match.loc[ii]\n",
    "        #ARGs\n",
    "        NewARG = str(temprow[1])\n",
    "        tempstr = Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Psi\"]\n",
    "        temptype = type(Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Psi\"])\n",
    "        if temptype == str:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Psi\"] = tempstr + \" \" + NewARG\n",
    "        else:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Psi\"] = NewARG\n",
    "\n",
    "\n",
    "#Finishing touches and output  \n",
    "Plastab.drop(columns=[\"Length\", \"GC\"], inplace=True)  \n",
    "Psi_Final = Pl_OF.merge(Plastab, how='left', on='Plasmid_ID')\n",
    "Psi_Final = Psi_Final[[\"Genus\",\"Organism\",\"AR_Bank_ID\",\"Plasmid_ID\",\"Length\",\"GC\",\"ARGs\",\"rep_type(s)\",\"relaxase_type(s)\",\"mpf_type\",\"orit_type(s)\",\"predicted_mobility\",\"predicted_host_range_overall_rank\",\"Virulence\",\"Restriction Enzymes\",\"Methylases\",\"Par\",\"Toxin\",\"Antitoxin\",\"Psi\"]].copy().drop_duplicates()\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "Psi_Final.to_csv(folderPath + \"Plasmid_TabPar_withHits_\"+ dt_string + \".csv\")\n",
    "print(\"Everything Finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAST results processing for Mating-Pair Stabilization Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerunning BLAST code for MPS (really should have made this a callable function)\n",
    "#Re running imports and file loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input the folder path (make sure it is r'path/') and filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "filename_psiBR = 'MPS/mps_02-07-23.txt'\n",
    "filenamePID = 'plasmidORF_IDs_12-14-22.txt'\n",
    "filenamePLid = 'plasmidIDs_01-23-23.txt'\n",
    "filenamePlOF = 'Plasmid_TabPsi_withHits_2023-02-06_19-32-56.csv'\n",
    "filenameORF_OF = 'InterPlasTabs/RGI_tab_12-14-22.csv'\n",
    "\n",
    "# Loading the Blast results files\n",
    "psiBR = pd.read_csv(folderPath + filename_psiBR, delimiter='\\t', header=None)\n",
    "psiBRNames = psiBR.columns\n",
    "psiBR = psiBR[psiBRNames[0:5]]\n",
    "psiBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "\n",
    "#Loading Output Files\n",
    "ORF_OF = pd.read_csv(folderPath + filenameORF_OF, delimiter=',', header=0)\n",
    "Pl_OF = pd.read_csv(folderPath + filenamePlOF, delimiter=',', header=0)\n",
    "\n",
    "# Loading the Plasmid ID files\n",
    "PlID = pd.read_csv(folderPath + filenamePID, delimiter='\\t', header=0)\n",
    "PLasmidID = pd.read_csv(folderPath + filenamePLid, delimiter='\\t', header=0)\n",
    "PLasmidID = PLasmidID.drop_duplicates()\n",
    "\n",
    "# Setting up the Thresholds\n",
    "PIDT = 80\n",
    "QcovT2 = 70\n",
    "EvalT = 10e-5\n",
    "counter = 0\n",
    "totalPlIDs = len(PlID)\n",
    "PsiBRIndexHit = []\n",
    "\n",
    "\n",
    "#Add Psi Protein Families to Blast Results tables\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "PsiAcc = pd.read_csv(folderPath + 'MPS/all_MPS_titles.csv', delimiter=',',header=0)\n",
    "psiBR = psiBR.merge(PsiAcc, how = 'inner', left_on = 'Query', right_on = 'ACC')\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkPsi = psiBR.Subject == i\n",
    "    if ChkPsi.sum() > 0:\n",
    "        tempDFPar = psiBR[ChkPsi]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFPar.index:\n",
    "            tempRowPar = tempDFPar.loc[iii]\n",
    "            if tempRowPar.PID >= PIDT and tempRowPar.Qcov >= QcovT2 and tempRowPar.Eval <= EvalT:\n",
    "                if tempRowPar.Qcov >= coverage:\n",
    "                    coverage = tempRowPar.Qcov\n",
    "                    current_best_idx = iii\n",
    "        PsiBRIndexHit = np.append(PsiBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"MPS Protein Blast Scanning Finished! You got \" + str(len(PsiBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "\n",
    "# Scan Hits and add to table\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "PsiHits = psiBR.iloc[PsiBRIndexHit] \n",
    "PsiOF = ORF_OF.merge(PsiHits, how='left', left_on='ORF_ID',right_on='Subject')\n",
    "PsiOF = PsiOF[[\"ORF_ID\", \"MPS\"]].copy().drop_duplicates()\n",
    "print(\"MPS Proteins Added \", len(PsiOF))\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "PsiOF.to_csv(folderPath + \"MPS_Tab_\"+ dt_string + \".csv\")\n",
    "print(\"All done!\")\n",
    "\n",
    "\n",
    "#Adding stuff to plasmid table\n",
    "Plastab = pd.read_csv(folderPath + 'Plasmid_tab2_01-09-23.csv', delimiter=',', header=0)\n",
    "ORFtab = PsiOF.dropna(subset=[\"MPS\"])\n",
    "#Identify plasmid ORFs and replace empty cells with hits from ORFs in plasmid table\n",
    "for i in tqdm(PLasmidID[\"Plasmid_ID\"]):\n",
    "    index = Plastab[Plastab.Plasmid_ID == i]\n",
    "    Chk = ORFtab[\"ORF_ID\"].str.contains(i)\n",
    "    match = ORFtab[Chk]\n",
    "    for ii in match.index:\n",
    "        temprow = match.loc[ii]\n",
    "        #ARGs\n",
    "        NewARG = str(temprow[1])\n",
    "        tempstr = Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"MPS\"]\n",
    "        temptype = type(Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"MPS\"])\n",
    "        if temptype == str:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"MPS\"] = tempstr + \" \" + NewARG\n",
    "        else:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"MPS\"] = NewARG\n",
    "\n",
    "\n",
    "#Finishing touches and output  \n",
    "Plastab.drop(columns=[\"Length\", \"GC\"], inplace=True)  \n",
    "Psi_Final = Pl_OF.merge(Plastab, how='left', on='Plasmid_ID')\n",
    "Psi_Final = Psi_Final[[\"Genus\",\"Organism\",\"AR_Bank_ID\",\"Plasmid_ID\",\"Length\",\"GC\",\"ARGs\",\"rep_type(s)\",\"relaxase_type(s)\",\"mpf_type\",\"orit_type(s)\",\"predicted_mobility\",\"predicted_host_range_overall_rank\",\"Virulence\",\"Restriction Enzymes\",\"Methylases\",\"Par\",\"Toxin\",\"Antitoxin\",\"Psi\",\"MPS\"]].copy().drop_duplicates()\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "Psi_Final.to_csv(folderPath + \"Plasmid_TabMPS_withHits_\"+ dt_string + \".csv\")\n",
    "print(\"Everything Finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from plotnine import *\n",
    "\n",
    "# Input the folder path (make sure it is r'path/') and filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "Plasfile = 'Plasmid_TabMPS_withHits_2023-02-07_14-11-15.csv'\n",
    "Plastab = pd.read_csv(folderPath + Plasfile, delimiter=',', header=0)\n",
    "\n",
    "#Making length into kb instead of bp\n",
    "Temptab = Plastab\n",
    "for index in Temptab.index:\n",
    "    length = Temptab[\"Length\"].loc[index]\n",
    "    Temptab[\"Length\"].loc[index] = length / 1000\n",
    "\n",
    "#Figure 1A\n",
    "Fig1A = (ggplot(Plastab) + \n",
    "         aes(x=\"Length\", fill=\"predicted_mobility\") + \n",
    "         geom_histogram(binwidth=10) + labs(x=\"Length (kb)\", y='Plasmids', fill='Predicted Mobility') + #Change bins=15 to binwidth=10 05/06/23\n",
    "         scale_fill_manual(values=['#117733', '#88CCEE', '#DDCC77'], labels=['Conjugative', 'Mobilizable', 'Non-Mobilizable']) + \n",
    "         theme_classic() +\n",
    "         theme(axis_text=element_text(size=10), axis_title=element_text(size=12), legend_title=element_text(size=12), legend_text=element_text(size=10))\n",
    ")\n",
    "ggplot.save(Fig1A, filename='Length_histF1A.pdf', dpi=300)\n",
    "\n",
    "#Figure 1B\n",
    "Fig1B = (ggplot(Plastab) + \n",
    "         aes(x=\"GC\", fill=\"predicted_mobility\") + \n",
    "         geom_histogram(bins=12) + labs(x=\"GC content (%)\", y='Plasmids', fill='Predicted Mobility') + \n",
    "         scale_fill_manual(values=['#117733', '#88CCEE', '#DDCC77'], labels=['Conjugative', 'Mobilizable', 'Non-Mobilizable']) + \n",
    "         theme_classic() +\n",
    "         theme(axis_text=element_text(size=10), axis_title=element_text(size=12), legend_title=element_text(size=12), legend_text=element_text(size=10))\n",
    ")\n",
    "ggplot.save(Fig1B, filename='GC_histF1B.pdf', dpi=300)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Incompatibility type results with rest of table to make Figure 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re running imports and file loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input the folder path (make sure it is r'path/') and filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "Old_results = 'Plasmid_Tab_withHits_2023-01-09_sed.csv'\n",
    "\n",
    "#Read results\n",
    "Old = pd.read_csv(folderPath + Old_results, delimiter=',', header=0)\n",
    "Oldinc = Old[[\"Plasmid_ID\", \"Inc_Type\"]].copy()\n",
    "print(len(Oldinc))\n",
    "oldnew = Oldinc[\"Inc_Type\"].str.split(\" \", n=0, expand=True)\n",
    "\n",
    "#Making tidy version of Inc data in table\n",
    "Oldinc[\"Inc1\"] = oldnew[0]\n",
    "Oldinc[\"Inc2\"] = oldnew[1]\n",
    "Oldinc[\"Inc3\"] = oldnew[2]\n",
    "Oldinc[\"Inc4\"] = oldnew[3]\n",
    "Oldinc[\"Inc5\"] = oldnew[4]\n",
    "Oldinc[\"Inc6\"] = oldnew[5]\n",
    "Oldinc[\"Inc7\"] = oldnew[6]\n",
    "Oldinc[\"Inc8\"] = oldnew[7]\n",
    "\n",
    "Oldinc.drop(columns=[\"Inc_Type\"], inplace=True)\n",
    "\n",
    "tempinc1 = Oldinc[[\"Plasmid_ID\", \"Inc1\"]].copy()\n",
    "tempinc1.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc2 = Oldinc[[\"Plasmid_ID\", \"Inc2\"]].copy()\n",
    "tempinc2.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc3 = Oldinc[[\"Plasmid_ID\", \"Inc3\"]].copy()\n",
    "tempinc3.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc4 = Oldinc[[\"Plasmid_ID\", \"Inc4\"]].copy()\n",
    "tempinc4.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc5 = Oldinc[[\"Plasmid_ID\", \"Inc5\"]].copy()\n",
    "tempinc5.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc6 = Oldinc[[\"Plasmid_ID\", \"Inc6\"]].copy()\n",
    "tempinc6.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc7 = Oldinc[[\"Plasmid_ID\", \"Inc7\"]].copy()\n",
    "tempinc7.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "tempinc8 = Oldinc[[\"Plasmid_ID\", \"Inc8\"]].copy()\n",
    "tempinc8.columns = [\"Plasmid_ID\", \"Inc_Type\"]\n",
    "\n",
    "OldNewInctab = pd.concat([tempinc1, tempinc2, tempinc3, tempinc4, tempinc5, tempinc6, tempinc7, tempinc8])\n",
    "OldNewInctab = OldNewInctab.dropna()\n",
    "print(len(OldNewInctab))\n",
    "\n",
    "#Getting Inc type counts\n",
    "Mergeymerge = Plastab.merge(OldNewInctab, how='outer', on='Plasmid_ID')\n",
    "NewIncPlastab = Mergeymerge.dropna(subset=[\"Inc_Type\"])\n",
    "NewIncPlastabtest = NewIncPlastab[NewIncPlastab[\"Inc_Type\"] != '']\n",
    "NewIncPlastabtest['Inc_Type_count'] = NewIncPlastabtest.groupby('Inc_Type')['Inc_Type'].transform('count')\n",
    "mobconjNewPlas = NewIncPlastabtest[NewIncPlastabtest[\"predicted_mobility\"] != \"non-mobilizable\"]\n",
    "mobconjNewPlas['Inc_Type_count'] = mobconjNewPlas.groupby('Inc_Type')['Inc_Type'].transform('count')\n",
    "\n",
    "#Figure 2A\n",
    "Fig2A = (ggplot(mobconjNewPlas) + \n",
    "         aes(x='reorder(Inc_Type, Inc_Type_count)', fill='predicted_mobility') + \n",
    "         coord_flip() + \n",
    "         labs(x='Incompatibility Type', y='Plasmids', fill='Predicted Mobility') + \n",
    "         geom_bar() + \n",
    "         theme_classic() + \n",
    "         scale_fill_manual(['#117733', '#88CCEE'], labels=['Conjugative', 'Mobilizable']) + \n",
    "         theme(axis_text=element_text(size=10), axis_title=element_text(size=12), legend_title=element_text(size=12), legend_text=element_text(size=10), figure_size=(10,8))\n",
    ")\n",
    "ggplot.save(Fig2A, filename='Inc_F2A.pdf', dpi=300)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Figures 2B and 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re running imports and file loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input the folder path (make sure it is r'path/') and filenames (due to changes made outside of python code, date numbers in names might not match with other cells)\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "Plasfile = 'Plasmid_TabMPS_withHits_2023-02-07_14-11-15.csv'\n",
    "Plastab = pd.read_csv(folderPath + Plasfile, delimiter=',', header=0)\n",
    "\n",
    "#Tidy version of relaxase data\n",
    "relaxtab = Plastab[[\"Plasmid_ID\", \"relaxase_type(s)\"]].copy()\n",
    "relaxnew = relaxtab[\"relaxase_type(s)\"].str.split(\",\", n=0, expand=True)\n",
    "\n",
    "relaxtab[\"Mob1\"] = relaxnew[0]\n",
    "relaxtab[\"Mob2\"] = relaxnew[1]\n",
    "relaxtab[\"Mob3\"] = relaxnew[2]\n",
    "\n",
    "relaxtab.drop(columns=[\"relaxase_type(s)\"], inplace=True)\n",
    "\n",
    "tempmob1 = relaxtab[[\"Plasmid_ID\", \"Mob1\"]].copy()\n",
    "tempmob1.columns = [\"Plasmid_ID\", \"relaxase_type\"]\n",
    "tempmob2 = relaxtab[[\"Plasmid_ID\", \"Mob2\"]].copy()\n",
    "tempmob2.columns = [\"Plasmid_ID\", \"relaxase_type\"]\n",
    "tempmob3 = relaxtab[[\"Plasmid_ID\", \"Mob3\"]].copy()\n",
    "tempmob3.columns = [\"Plasmid_ID\", \"relaxase_type\"]\n",
    "\n",
    "NewMobtab = pd.concat([tempmob1, tempmob2, tempmob3,])\n",
    "NewMobtab = NewMobtab.dropna()\n",
    "MergeymergeMOB = Plastab.merge(NewMobtab, how='outer', on='Plasmid_ID')\n",
    "NewMobPlastab = MergeymergeMOB.dropna(subset=[\"relaxase_type\"])\n",
    "NewMobPlastab.drop_duplicates(inplace=True)\n",
    "\n",
    "#Figure 2B\n",
    "Fig2B = (ggplot(NewMobPlastab) + \n",
    "         aes(x='relaxase_type', fill='relaxase_type') + \n",
    "         labs(x='MOB Type', y='Plasmids', fill='MOB Type') + \n",
    "         geom_bar(show_legend=False) + \n",
    "         theme_classic() + \n",
    "         scale_x_discrete(limits=[\"MOBF\", \"MOBP\", \"MOBH\", \"MOBC\", \"MOBQ\", \"MOBV\"]) + \n",
    "         scale_fill_manual(values=['#E69F00', '#CC79A7', '#009E73', '#F0E442', '#0072B2', '#D55E00']) + \n",
    "         theme(axis_text=element_text(size=10), axis_title=element_text(size=12), legend_title=element_text(size=12), legend_text=element_text(size=10)))\n",
    "Fig2B.save(filename='Mob_F2B.pdf', dpi=300)\n",
    "\n",
    "#Table manipulation for Figure 2C\n",
    "NewMPFPlastab = Plastab[Plastab[\"mpf_type\"] != '-']\n",
    "print(\"Plasmids with MPF_types, \", len(NewMPFPlastab))\n",
    "ProtSec = NewMPFPlastab[NewMPFPlastab[\"predicted_mobility\"] != 'conjugative']\n",
    "trueFig2Ctab = NewMPFPlastab[NewMPFPlastab[\"predicted_mobility\"] != 'non-mobilizable']\n",
    "MPFF = trueFig2Ctab[trueFig2Ctab[\"mpf_type\"].str.contains(\"MPF_F\")]\n",
    "MPFT = trueFig2Ctab[trueFig2Ctab[\"mpf_type\"].str.contains(\"MPF_T\")]\n",
    "MPFI = trueFig2Ctab[trueFig2Ctab[\"mpf_type\"].str.contains(\"MPF_I\")]\n",
    "MPFG = trueFig2Ctab[trueFig2Ctab[\"mpf_type\"].str.contains(\"MPF_G\")]\n",
    "print(\"Plasmids with MPF_F systems, \", len(MPFF))\n",
    "print(\"Plasmids with MPF_T systems, \", len(MPFT))\n",
    "print(\"Plasmids with MPF_I systems, \", len(MPFI))\n",
    "print(\"Plasmids with MPF_G systems, \", len(MPFG))\n",
    "\n",
    "#Figure 2C\n",
    "MPFtabnew = Plastab[Plastab[\"mpf_type\"] != '-']\n",
    "Fig2C = (ggplot(MPFtabnew) + \n",
    "         aes(x=\"mpf_type\", fill=\"mpf_type\") + \n",
    "         geom_bar(show_legend=False) + \n",
    "         labs(x=\"MPF Type\", y=\"Plasmids\", fill='MOB Type') + \n",
    "         scale_x_discrete(limits=['MPF_F', 'MPF_T', 'MPF_I', 'MPF_G']) + \n",
    "         scale_fill_manual(values=['#785EF0', '#FFB000', '#FE6100', '#DC267F']) + \n",
    "         theme_classic() + \n",
    "         theme(axis_text=element_text(size=10), axis_title=element_text(size=12), legend_title=element_text(size=12), legend_text=element_text(size=10)))\n",
    "Fig2C.save(filename='MPF_F2C.pdf', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scikit_posthocs as sph\n",
    "\n",
    "#Folder and filenames\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "Plasfile = 'Plasmid_Tab_Full_02-10-23.csv'\n",
    "Plastab = pd.read_csv(folderPath + Plasfile, delimiter=',', header=0)\n",
    "\n",
    "#Subtables\n",
    "conjtab = Plastab[Plastab[\"predicted_mobility\"] == 'conjugative']\n",
    "mobtab = Plastab[Plastab[\"predicted_mobility\"] == 'mobilizable']\n",
    "nonmobtab = Plastab[Plastab[\"predicted_mobility\"] == 'non-mobilizable']\n",
    "\n",
    "#Get easy results\n",
    "print(\"Conjugative Plasmids, \", len(conjtab))\n",
    "print(\"Mobilizable Plasmids, \", len(mobtab))\n",
    "print(\"Non-mobilizable Plasmids, \", len(nonmobtab))\n",
    "print(Plastab[\"Length\"].min())\n",
    "print(Plastab[\"Length\"].max())\n",
    "print(Plastab[\"Length\"].median())\n",
    "\n",
    "#Assign a number for predicted mobility\n",
    "Plastab[\"mobility_num\"] = ''\n",
    "\n",
    "for i in Plastab.index:\n",
    "    temprow = Plastab.loc[i]\n",
    "    if temprow[\"predicted_mobility\"] == 'non-mobilizable':\n",
    "        Plastab.at[i, \"mobility_num\"] = 0\n",
    "    elif temprow[\"predicted_mobility\"] == 'mobilizable':\n",
    "        Plastab.at[i, \"mobility_num\"] = 1\n",
    "    elif temprow[\"predicted_mobility\"] == 'conjugative':\n",
    "        Plastab.at[i, \"mobility_num\"] = 2\n",
    "\n",
    "#Kruskal-Wallis followed by Dunn's for Length and mobility\n",
    "testtab = Plastab[[\"Length\", \"mobility_num\"]].copy()\n",
    "print(\"Length min, \", testtab[\"Length\"].min())\n",
    "print(\"Length max, \", testtab[\"Length\"].max())\n",
    "print(\"Length median, \", testtab[\"Length\"].median())\n",
    "print(stats.kruskal(testtab[\"Length\"], testtab[\"mobility_num\"]))\n",
    "sph.posthoc_dunn(testtab, val_col=\"Length\", group_col=\"mobility_num\", p_adjust = 'bonferroni')\n",
    "\n",
    "#Kruskal-Wallis followed by Dunn's for GC and mobility\n",
    "testGC = Plastab[[\"GC\", \"mobility_num\"]].copy()\n",
    "print(\"GC min, \", testGC[\"GC\"].min())\n",
    "print(\"GC max, \", testGC[\"GC\"].max())\n",
    "print(\"GC median, \", testGC[\"GC\"].median())\n",
    "print(stats.kruskal(testGC[\"GC\"], testGC[\"mobility_num\"]))\n",
    "sph.posthoc_dunn(testGC, val_col='GC', group_col='mobility_num', p_adjust='bonferroni')\n",
    "\n",
    "#Tidy version of ARG data to get relationship between presence of ARGs and mobility\n",
    "rgitab = Plastab[[\"Plasmid_ID\", \"ARGs\"]].copy()\n",
    "new = rgitab[\"ARGs\"].str.lstrip(\" \").str.split(\" \", n=0, expand=True)\n",
    "rgitab.drop(columns=[\"ARGs\"], inplace=True)\n",
    "pd_list = []\n",
    "\n",
    "for i in range(new.columns.__len__()):\n",
    "    rgitab[\"Inc{}\".format(i+1)] = new[i]\n",
    "    tempinc1 = rgitab[[\"Plasmid_ID\", \"Inc{}\".format(i+1)]].copy()\n",
    "    tempinc1.columns = [\"Plasmid_ID\", \"ARGs\"]\n",
    "    pd_list.append(tempinc1)\n",
    "\n",
    "rgibig = pd.concat(pd_list)\n",
    "rgibig = rgibig.dropna()\n",
    "droptab = Plastab.drop(columns='ARGs')\n",
    "rgibig = rgibig.merge(droptab, how='right', on='Plasmid_ID')\n",
    "\n",
    "#Assign numbers for stats\n",
    "rgibig[\"mobility_num\"] = ''\n",
    "rgibig['ARGyesno'] = ''\n",
    "\n",
    "for i in rgibig.index:\n",
    "    temprow = rgibig.loc[i]\n",
    "    if temprow[\"predicted_mobility\"] == 'non-mobilizable':\n",
    "        rgibig.at[i, \"mobility_num\"] = 0\n",
    "    elif temprow[\"predicted_mobility\"] == 'mobilizable':\n",
    "        rgibig.at[i, \"mobility_num\"] = 1\n",
    "    elif temprow[\"predicted_mobility\"] == 'conjugative':\n",
    "        rgibig.at[i, \"mobility_num\"] = 2\n",
    "\n",
    "for i in rgibig.index:\n",
    "    temprow = rgibig.loc[i]\n",
    "    if temprow[\"ARGs\"] == '':\n",
    "        rgibig.at[i, \"PlasmidARGcount\"] = 0\n",
    "        rgibig.at[i, \"ARGyesno\"] = 0\n",
    "    else:\n",
    "        rgibig.at[i, \"ARGyesno\"] = 1\n",
    "\n",
    "#Kruskal-Wallis followed by Dunn's for ARGs and mobility\n",
    "rgishort = rgibig[[\"Plasmid_ID\", \"PlasmidARGcount\", \"ARGyesno\", \"mobility_num\"]].copy().drop_duplicates()\n",
    "print(stats.kruskal(rgishort[\"ARGyesno\"], rgishort[\"mobility_num\"]))\n",
    "sph.posthoc_dunn(rgishort, val_col=\"ARGyesno\", group_col=\"mobility_num\", p_adjust = 'bonferroni')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAST results processing for Toxin-Antitoxin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "#Rerunning BLAST code for ToxAntitox again (really should have made this a callable function)\n",
    "filename_tatBR = 'Toxin_Antitoxin/Toxin-AT_02-02-23.txt'\n",
    "filenamePID = 'plasmidORF_IDs_12-14-22.txt'\n",
    "filenamePLid = 'plasmidIDs_01-23-23.txt'\n",
    "filenamePlOF = 'Plasmid_Tab_Full_02-10-23.csv'\n",
    "filenameORF_OF = 'InterPlasTabs/RGI_tab_12-14-22.csv'\n",
    "\n",
    "# Loading the Blast results files\n",
    "psiBR = pd.read_csv(folderPath + filename_tatBR, delimiter='\\t', header=None)\n",
    "psiBRNames = psiBR.columns\n",
    "psiBR = psiBR[psiBRNames[0:5]]\n",
    "psiBR.columns = [\"Query\",\"Subject\",\"PID\",\"Qcov\",\"Eval\"]\n",
    "\n",
    "#Loading Output Files\n",
    "ORF_OF = pd.read_csv(folderPath + filenameORF_OF, delimiter=',', header=0)\n",
    "Pl_OF = pd.read_csv(folderPath + filenamePlOF, delimiter=',', header=0)\n",
    "\n",
    "# Loading the Plasmid ID files\n",
    "PlID = pd.read_csv(folderPath + filenamePID, delimiter='\\t', header=0)\n",
    "PLasmidID = pd.read_csv(folderPath + filenamePLid, delimiter='\\t', header=0)\n",
    "PLasmidID = PLasmidID.drop_duplicates()\n",
    "\n",
    "# Setting up the Thresholds\n",
    "PIDT = 50\n",
    "QcovT2 = 70\n",
    "EvalT = 10e-5\n",
    "counter = 0\n",
    "totalPlIDs = len(PlID)\n",
    "PsiBRIndexHit = []\n",
    "\n",
    "\n",
    "#Add Psi Protein Families to Blast Results tables\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "TAcc = pd.read_csv(folderPath + 'Toxin_Antitoxin/TADB_T_acc_sed.csv', delimiter=',',header=0)\n",
    "TAcc.drop(columns=\"Antitoxin\", inplace=True)\n",
    "ATAcc = pd.read_csv(folderPath + 'Toxin_Antitoxin/TADB_AT_acc_sed.csv', delimiter=',', header=0)\n",
    "ATAcc.drop(columns=\"Toxin\", inplace=True)\n",
    "psiBR1 = psiBR.merge(TAcc, how = 'left', left_on = 'Query', right_on = 'TTA_ID')\n",
    "psiBR1.drop(columns=\"Organism\", inplace=True)\n",
    "psiBR = psiBR1.merge(ATAcc, how = 'left', left_on = 'Query', right_on = 'ATTA_ID')\n",
    "psiBR.drop(columns=\"Organism\", inplace=True)\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "for i in tqdm(PlID[\"ORF_ID\"]):\n",
    "    ChkPsi = psiBR.Subject == i\n",
    "    if ChkPsi.sum() > 0:\n",
    "        tempDFPar = psiBR[ChkPsi]\n",
    "        coverage, current_best_idx = 0, 0\n",
    "        for iii in tempDFPar.index:\n",
    "            tempRowPar = tempDFPar.loc[iii]\n",
    "            if tempRowPar.PID >= PIDT and tempRowPar.Qcov >= QcovT2 and tempRowPar.Eval <= EvalT:\n",
    "                if tempRowPar.Qcov >= coverage:\n",
    "                    coverage = tempRowPar.Qcov\n",
    "                    current_best_idx = iii\n",
    "        PsiBRIndexHit = np.append(PsiBRIndexHit,current_best_idx)\n",
    "    counter+=1\n",
    "print(\"Toxin_AT Protein Blast Scanning Finished! You got \" + str(len(PsiBRIndexHit)) + \" hits out of \" + str(totalPlIDs) + \" ORFs.\")\n",
    "counter = 0\n",
    "\n",
    "# Scan Hits and add to table\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "PsiHits = psiBR.iloc[PsiBRIndexHit]\n",
    "PsiHits.drop(columns=[\"Unnamed: 4_x\", \"Unnamed: 4_y\"], inplace=True)\n",
    "PsiOF = ORF_OF.merge(PsiHits, how='inner', left_on='ORF_ID',right_on='Subject')\n",
    "PsiOF = PsiOF[[\"ORF_ID\", \"Toxin\", \"Antitoxin\"]].copy().drop_duplicates()\n",
    "print(\"Toxin_AT Proteins Added \", len(PsiOF))\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "PsiOF.to_csv(folderPath + \"Toxin_AT\"+ dt_string + \".csv\")\n",
    "print(\"All done!\")\n",
    "\n",
    "\n",
    "#Adding stuff to plasmid table\n",
    "Plastab = pd.read_csv(folderPath + 'Plasmid_tab2_01-09-23.csv', delimiter=',', header=0)\n",
    "ORFtabTox = PsiOF.dropna(subset=[\"Toxin\"])\n",
    "ORFtabTox.drop(columns='Antitoxin', inplace=True)\n",
    "ORFtabAntitox = PsiOF.dropna(subset=[\"Antitoxin\"])\n",
    "ORFtabAntitox.drop(columns='Toxin', inplace=True)\n",
    "#Identify plasmid ORFs and replace empty cells with hits from ORFs in plasmid table\n",
    "for i in tqdm(PLasmidID[\"Plasmid_ID\"]):\n",
    "    index = Plastab[Plastab.Plasmid_ID == i]\n",
    "    Chk = ORFtabTox[\"ORF_ID\"].str.contains(i)\n",
    "    AntitoxChk = ORFtabAntitox[\"ORF_ID\"].str.contains(i)\n",
    "    toxmatch = ORFtabTox[Chk]\n",
    "    antitoxmatch = ORFtabAntitox[AntitoxChk]\n",
    "    for ii in toxmatch.index:\n",
    "        temprow = toxmatch.loc[ii]\n",
    "        #Tox\n",
    "        NewARG1 = str(temprow[1])\n",
    "        tempstr = Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Toxin\"]\n",
    "        temptype = type(Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Toxin\"])\n",
    "        if temptype == str:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Toxin\"] = tempstr + \" \" + NewARG1\n",
    "        else:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Toxin\"] = NewARG1\n",
    "    for ii in antitoxmatch.index:\n",
    "        temprow = antitoxmatch.loc[ii]\n",
    "        #AntiTox\n",
    "        NewARG2 = str(temprow[1])\n",
    "        tempstr = Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Antitoxin\"]\n",
    "        temptype = type(Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Antitoxin\"])\n",
    "        if temptype == str:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Antitoxin\"] = tempstr + \" \" + NewARG2\n",
    "        else:\n",
    "            Plastab.at[Plastab[Plastab.Plasmid_ID == i].index[0],\"Antitoxin\"] = NewARG2\n",
    "\n",
    "\n",
    "#Finishing touches and output  \n",
    "Plastab.drop(columns=[\"Length\", \"GC\"], inplace=True)  \n",
    "Psi_Final = Pl_OF.merge(Plastab, how='inner', on='Plasmid_ID')\n",
    "Psi_Final = Psi_Final[[\"Genus\",\"Organism\",\"AR_Bank_ID\",\"Plasmid_ID\",\"Length\",\"GC\",\"ARGs\",\"rep_type(s)\",\"relaxase_type(s)\",\"mpf_type\",\"orit_type(s)\",\"predicted_mobility\",\"predicted_host_range_overall_rank\",\"Virulence\",\"Restriction Enzymes\",\"Methylases\", \"Par\",\"Psi\",\"MPS\",\"Toxin\",\"Antitoxin\", \"RNA_Antitoxins\"]].copy().drop_duplicates()\n",
    "now = dt.datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "Psi_Final.to_csv(folderPath + \"Plasmid_TabToxin_AT_withHits_\"+ dt_string + \".csv\")\n",
    "print(\"Everything Finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making upsetplot (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from upsetplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "Plasfile = 'Plasmid_TabToxin_AT_withHits_2023-02-20_19-33-37.csv'\n",
    "Plastab = pd.read_csv(folderPath + Plasfile, delimiter=',', header=0)\n",
    "mobconjtab = Plastab[Plastab[\"predicted_mobility\"] != 'non-mobilizable']\n",
    "upsettab = mobconjtab[[\"Plasmid_ID\", \"Methylases\", \"Par\", \"Toxin\", \"Antitoxin\", \"RNA_Antitoxins\", \"Psi\", \"MPS\"]].copy()\n",
    "upsettab = upsettab.replace(r'^\\s+$', np.nan, regex=True)\n",
    "upsetfinal = pd.DataFrame(columns = [\"Plasmid_ID\",\"Methyltransferases\", \"Partitioning\", \"Toxin-Antitoxin\", \"SOS Inhibition\", \"Mating-Pair Stabilization\"])\n",
    "upsetfinal[\"Plasmid_ID\"] = upsettab[\"Plasmid_ID\"]\n",
    "print(len(upsettab))\n",
    "#Methylases\n",
    "for i in tqdm(upsettab.index):\n",
    "    temprow = upsettab.loc[i]\n",
    "    tempid = temprow[\"Plasmid_ID\"]\n",
    "    temptype = type(temprow[\"Methylases\"])\n",
    "    if temptype != str:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Methyltransferases\"] = 'False'\n",
    "    else:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Methyltransferases\"] = 'True'\n",
    "\n",
    "#Partitioning\n",
    "for i in tqdm(upsettab.index):\n",
    "    temprow = upsettab.loc[i]\n",
    "    tempid = temprow[\"Plasmid_ID\"]\n",
    "    temptype = type(temprow[\"Par\"])\n",
    "    if temptype != str:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Partitioning\"] = 'False'\n",
    "    else:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Partitioning\"] = 'True'\n",
    "\n",
    "#Toxin-Antitoxin\n",
    "for i in tqdm(upsettab.index):\n",
    "    temprow = upsettab.loc[i]\n",
    "    tempid = temprow[\"Plasmid_ID\"]\n",
    "    temptypeT = type(temprow[\"Toxin\"])\n",
    "    temptypeAT = type(temprow[\"Antitoxin\"])\n",
    "    temptypeATR = type(temprow[\"RNA_Antitoxins\"])\n",
    "    if temptypeT != str:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Toxin-Antitoxin\"] = 'False'\n",
    "    elif temptypeAT != str and temptypeATR != str:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Toxin-Antitoxin\"] = 'False'\n",
    "    else:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Toxin-Antitoxin\"] = 'True'\n",
    "\n",
    "#SOS Inhibition\n",
    "for i in tqdm(upsettab.index):\n",
    "    temprow = upsettab.loc[i]\n",
    "    tempid = temprow[\"Plasmid_ID\"]\n",
    "    temptype = type(temprow[\"Psi\"])\n",
    "    if temptype != str:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"SOS Inhibition\"] = 'False'\n",
    "    else:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"SOS Inhibition\"] = 'True'\n",
    "\n",
    "#MPS\n",
    "for i in tqdm(upsettab.index):\n",
    "    temprow = upsettab.loc[i]\n",
    "    tempid = temprow[\"Plasmid_ID\"]\n",
    "    temptype = type(temprow[\"MPS\"])\n",
    "    if temptype != str:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Mating-Pair Stabilization\"] = 'False'\n",
    "    else:\n",
    "        upsetfinal.at[upsetfinal[upsetfinal[\"Plasmid_ID\"] == tempid].index[0], \"Mating-Pair Stabilization\"] = 'True'\n",
    "\n",
    "upsetfinal = upsetfinal[[\"Plasmid_ID\",\"Methyltransferases\",\"Partitioning\",\"Toxin-Antitoxin\",\"SOS Inhibition\",\"Mating-Pair Stabilization\"]].copy()\n",
    "print(len(upsetfinal))\n",
    "for i in upsetfinal.index:\n",
    "    temprow = upsetfinal.loc[i]\n",
    "    if temprow[\"Methyltransferases\"] == 'False' and temprow[\"Partitioning\"] == 'False' and temprow[\"Toxin-Antitoxin\"] == 'False' and temprow[\"SOS Inhibition\"] == 'False' and temprow[\"Mating-Pair Stabilization\"] == 'False':\n",
    "        upsetfinal.drop(labels=i, inplace=True)\n",
    "\n",
    "upsetfinal[\"Methyltransferases\"]= upsetfinal[\"Methyltransferases\"].apply(lambda x: True if x == \"True\" else False)\n",
    "upsetfinal[\"Partitioning\"]= upsetfinal[\"Partitioning\"].apply(lambda x: True if x == \"True\" else False)\n",
    "upsetfinal[\"Toxin-Antitoxin\"]= upsetfinal[\"Toxin-Antitoxin\"].apply(lambda x: True if x == \"True\" else False)\n",
    "upsetfinal[\"SOS Inhibition\"]= upsetfinal[\"SOS Inhibition\"].apply(lambda x: True if x == \"True\" else False)\n",
    "upsetfinal[\"Mating-Pair Stabilization\"]= upsetfinal[\"Mating-Pair Stabilization\"].apply(lambda x: True if x == \"True\" else False)\n",
    "\n",
    "\n",
    "print(len(upsetfinal))\n",
    "\n",
    "\n",
    "#Figure 3\n",
    "plot(upsetfinal, show_counts='{:d}', min_degree=3)\n",
    "plt.savefig('Fig3_upset_TATfixed.pdf', dpi=300) #I had made a previous version of this file with incorrect toxin-antitoxin data. This notebook only contains the correct code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Supplementary Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "\n",
    "#Folder and filenames and reading results\n",
    "folderPath = r'/workdir/users/hgl28/CDC_Isolates/Post-Dec2022/'\n",
    "Plasfile = 'Plasmid_TabToxin_AT_withHits_2023-02-20_19-33-37.csv'\n",
    "RGIfile = 'RGI_BLAST_results/rgi_plasmidORFs.tsv'\n",
    "Plastab = pd.read_csv(folderPath + Plasfile, delimiter=',', header=0)\n",
    "RGIresults = pd.read_csv(folderPath + RGIfile, delimiter='\\t', header=0)\n",
    "\n",
    "#Tidy version of ARG data\n",
    "rgitab = Plastab[[\"Plasmid_ID\", \"ARGs\"]].copy()\n",
    "new = rgitab[\"ARGs\"].str.lstrip(\" \").str.split(\" \", n=0, expand=True)\n",
    "rgitab.drop(columns=[\"ARGs\"], inplace=True)\n",
    "pd_list = []\n",
    "\n",
    "for i in range(new.columns.__len__()):\n",
    "    rgitab[\"Inc{}\".format(i+1)] = new[i]\n",
    "    tempinc1 = rgitab[[\"Plasmid_ID\", \"Inc{}\".format(i+1)]].copy()\n",
    "    tempinc1.columns = [\"Plasmid_ID\", \"ARGs\"]\n",
    "    pd_list.append(tempinc1)\n",
    "\n",
    "rgibig = pd.concat(pd_list)\n",
    "rgibig = rgibig.dropna()\n",
    "droptab = Plastab.drop(columns='ARGs')\n",
    "rgibig = rgibig.merge(droptab, how='right', on='Plasmid_ID')\n",
    "rgibig[\"Drug_Class\"] = ''\n",
    "\n",
    "#Getting drug class information for problematic drug class names\n",
    "for i in rgibig.index:\n",
    "    hitindex = RGIresults[\"ORF_ID\"].str.contains(rgibig.at[i,\"Plasmid_ID\"])\n",
    "    hits = RGIresults[hitindex]\n",
    "    if len(hits) > 0:\n",
    "        for ii in hits.index:\n",
    "            tempARG = pd.Series(rgibig.at[i, \"ARGs\"])\n",
    "            check = tempARG.isin([hits.at[ii, \"Best_Hit_ARO\"]])\n",
    "            if check[0] == True:\n",
    "                rgibig.at[i, \"Drug_Class\"] = hits.at[ii, \"Drug Class\"]\n",
    "            elif tempARG[0] == 'catII_K12':\n",
    "                rgibig.at[i, \"Drug_Class\"] = 'phenicol antibiotic'\n",
    "            elif tempARG[0] == 'PC1_beta-lactamase_(blaZ)':\n",
    "                rgibig.at[i, \"Drug_Class\"] = 'penam'\n",
    "            elif tempARG[0] == 'S.aureus_mupA':\n",
    "                rgibig.at[i, \"Drug_Class\"] = 'mupirocin'\n",
    "\n",
    "#Getting drug class information for everything else\n",
    "for i in rgibig.index:\n",
    "    if rgibig.at[i, \"Drug_Class\"] == 'aminoglycoside antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Aminoglycosides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'sulfonamide antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Sulfonamides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'disinfecting agents and antiseptics':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Antiseptics'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'monobactam; cephalosporin; penam; penem':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'carbapenem; cephalosporin; penam':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'diaminopyrimidine antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Diaminopyrimidines'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'tetracycline antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Tetracyclines'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'macrolide antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Macrolides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'phenicol antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Phenicols'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'carbapenem; cephalosporin; cephamycin; penam':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'monobactam; carbapenem; cephalosporin; penam':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'glycopeptide antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Glycopeptides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'cephalosporin; penam':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'fluoroquinolone antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Fluoroquinolones'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'fluoroquinolone antibiotic; aminoglycoside antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Aminoglycosides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'penam':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'rifamycin antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Rifamycins'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'macrolide antibiotic; streptogramin antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Macrolides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'cephamycin':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'cephalosporin; cephamycin':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'carbapenem; cephalosporin; cephamycin; penam; penem':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'macrolide antibiotic; lincosamide antibiotic; streptogramin antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Macrolides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'macrolide antibiotic; lincosamide antibiotic; streptogramin antibiotic; streptogramin A antibiotic; streptogramin B antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Macrolides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'macrolide antibiotic; streptogramin antibiotic; streptogramin B antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Macrolides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'nucleoside antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Nucleosides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'cephalosporin':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'cephalosporin; penam; penem':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'peptide antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Peptides'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'monobactam; cephalosporin':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Beta-lactams'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'fluoroquinolone antibiotic; tetracycline antibiotic':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Tetracyclines'\n",
    "    elif rgibig.at[i, \"Drug_Class\"] == 'mupirocin':\n",
    "        rgibig.at[i, \"Drug_Class\"] = 'Mupirocin'\n",
    "\n",
    "#Counts for plotting\n",
    "rgibig['PlasmidARGcount'] = rgibig.groupby('Plasmid_ID')['Plasmid_ID'].transform('count')\n",
    "rgibig[\"DrugClassCount\"] = rgibig.groupby('Drug_Class')['Drug_Class'].transform('count')\n",
    "rginoz = rgibig[rgibig[\"Drug_Class\"] != '']\n",
    "\n",
    "\n",
    "#Supplementary Figure 1A\n",
    "SF1A_ARGsclass = (ggplot(rginoz) + \n",
    "          aes(x='reorder(Drug_Class, DrugClassCount)', fill='predicted_mobility') + \n",
    "          geom_bar() + \n",
    "          labs(x='Resistance Class', y='Number of Genes', fill='Predicted Mobility') + \n",
    "          theme_classic() + \n",
    "          coord_flip() + \n",
    "          scale_fill_manual(values=['#117733', '#88CCEE', '#DDCC77'], labels=['Conjugative', 'Mobilizable', 'Non-Mobilizable']))\n",
    "SF1A_ARGsclass.save(filename='SF1A_ARGclass.pdf', dpi=300)\n",
    "\n",
    "#Supplementary Figure 1B\n",
    "rgishort = rgibig[[\"Plasmid_ID\", \"PlasmidARGcount\"]].copy().drop_duplicates()\n",
    "argfigtabV2 = Plastab.merge(rgishort, how='left', on='Plasmid_ID')\n",
    "SFGARGfigB = (ggplot(argfigtabV2) +\n",
    "           aes(x='PlasmidARGcount', fill='predicted_mobility') + \n",
    "           geom_histogram(bins=12) + \n",
    "           labs(x='Number of ARGs', y='Plasmids', fill='Predicted Mobility') + \n",
    "           theme_classic() + \n",
    "           scale_fill_manual(values=['#117733', '#88CCEE', '#DDCC77'], labels=[\"Conjugative\", \"Mobilizable\", \"Non-Mobilizable\"]))\n",
    "SFGARGfigB.save(filename=\"SF1B_ARGcounts.pdf\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2262475e6aa45d1d223cc67f1fc06ecf8bf0615ea8be9d538453c3516ff768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
